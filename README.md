# NLP Text Preprocessing Techniques ðŸ§ ðŸ“š

This repository contains essential text preprocessing techniques widely used in Natural Language Processing (NLP) tasks. These foundational methods help prepare raw text data for downstream machine learning and deep learning applications.

## ðŸ”§ Implemented Techniques

Each notebook in this repository demonstrates a key preprocessing step with practical examples:

1. **Tokenization**  
   Splits raw text into individual words or tokens using Python and NLP libraries like NLTK and spaCy.

2. **Stop Words Removal**  
   Filters out common words (e.g., *the*, *is*, *and*) that may not carry significant meaning in NLP analysis.

3. **Stemming**  
   Reduces words to their root form using algorithms like PorterStemmer (e.g., *running* â†’ *run*).

4. **Lemmatization**  
   Maps words to their base or dictionary form, using context-aware tools like WordNetLemmatizer.

5. **Bag of Words & TF-IDF Vectorization**  
   Converts textual data into numerical feature vectors using BoW and TF-IDF techniques for model input.

## ðŸ’¡ Libraries Used

- `NLTK`
- `spaCy`
- `Scikit-learn`
- `Pandas`
- `NumPy`


## ðŸ“Œ Purpose

These notebooks serve as a quick reference for beginners and practitioners to understand and implement standard NLP preprocessing workflows.


